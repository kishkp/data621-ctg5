---
title: "Home Work Assignment - 04"
author: "Critical Thinking Group 5"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
---

\newpage

# Overview 
The data set contains approximately 8161 records. Each record represents a customer profile at an auto insurance company. Each record has two response variables. The first response variable, TARGET_FLAG, is a 1 or a 0. A "1" means that the person was in a car crash. A zero means that the person was not in a car crash. The second response variable is TARGET_AMT. This value is zero
if the person did not crash their car. But if they did crash their car, this number will be a value greater than zero.
\

\
We will be exploring, analyzing, and modeling the training data to build many binary logistic regression models (to predict if a person will crash the car) and also some linear regression models (to predict the amount of money it will take to fix the car after crashing). Out of the many models for each task, we will go ahead and shortlist one model that works the best. We will then use these models (one for each task) on the test / evaluation data.

\

To attain our objective, we will be following the below best practice steps and guidelines: \

1 -Data Exploration \
2 -Data Preparation \
3 -Build Models \
4 -Select Models \

\
\

As a strategy, we will split the train dataset into 2 parts - TRAIN and VALID. In the VALID dataset, we will hold out some values to validate how well the model is trained using the TRAIN dataset.
\
\
We will do this once all the data transformations are complete and we are ready to build the models.
\
\

While building and selecting models, We will deal with the problem in 2 parts: \

- Part 1 - Here we build and select Binary Logistic Regression models using the training data set. 
\

- Part 2 - Here we build and select Linear Regression models using only the "Crashed" data from the training data set.

\
\


#1 Data Exploration Analysis

In section we will explore and gain some insights into the dataset by pursuing the below high level steps and inquiries: \
-Variable identification \
-Variable Relationships \
-Data summary analysis \
-Outliers and Missing Values Identification


##1.1	Variable identification

First let's display and examine the data dictionary or the data columns as shown in table 1

```{r, echo = FALSE, warning=FALSE, message=FALSE}

if (!require("ggplot2",character.only = TRUE)) (install.packages("ggplot2",dep=TRUE))
if (!require("MASS",character.only = TRUE)) (install.packages("MASS",dep=TRUE))
if (!require("knitr",character.only = TRUE)) (install.packages("knitr",dep=TRUE))
if (!require("xtable",character.only = TRUE)) (install.packages("xtable",dep=TRUE))
if (!require("dplyr",character.only = TRUE)) (install.packages("dplyr",dep=TRUE))
if (!require("psych",character.only = TRUE)) (install.packages("psych",dep=TRUE))
if (!require("stringr",character.only = TRUE)) (install.packages("stringr",dep=TRUE))
if (!require("car",character.only = TRUE)) (install.packages("car",dep=TRUE))
if (!require("faraway",character.only = TRUE)) (install.packages("faraway",dep=TRUE))
if (!require("dummy",character.only = TRUE)) (install.packages("dummy",dep=TRUE))
if (!require("reshape2",character.only = TRUE)) (install.packages("reshape2",dep=TRUE))
if (!require("popbio",character.only = TRUE)) (install.packages("popbio",dep=TRUE))


library(ggplot2)
library(MASS)
library(knitr)
library(xtable)
library(dplyr)
library(psych)
library(stringr)
library(car)
library(faraway)
library(dummy)
library(reshape2)
library(popbio)

insure_train_full <- read.csv("https://raw.githubusercontent.com/kishkp/data621-ctg5/master/HW4/insurance_training_data.csv")

insurevars <- read.csv("https://raw.githubusercontent.com/kishkp/data621-ctg5/master/HW4/insurevars.csv")
#insurevars <- insurevars[str_trim(insurevars[,1])!="INDEX",] 

kable(insurevars, caption = "Variable Description")

#insure_test <- read.csv("https://raw.githubusercontent.com/kishkp/data621-ctg5/master/HW4/insurance-evaluation-data.csv")

#str(city_crime_test)


```

We notice that there are 2 dependent variables - TARGET_FLAG and TARGET_AMT. Apart from these 2 dependent variables, we have 23 independent or predictor variables.\
\

```{r}
str(insure_train_full)

levels(insure_train_full$MSTATUS)
levels(insure_train_full$SEX)
levels(insure_train_full$EDUCATION)
levels(insure_train_full$JOB)
levels(insure_train_full$CAR_TYPE)
levels(insure_train_full$URBANICITY)
#levels(insure_train_full$REVOKED)
```
\
\

From the output above we can make the following observations:\


- some numeric variables like INCOME, HOME_VAL, BLUEBOOK, OLDCLAIM have been converted to Factor variables. This needs to be set right.

- Some of the variables like MSTATUS, SEX, EDUCATION, JOB, CAR_TYPE, URBANICITY have some of the values encoded with "z_". Not that this will impact the analysis, but it will look a bit odd. So we will be fixing this.

- EDUCATION has 2 "High School" values - one starting with "<" and another starting with "z_". It is assumed that both these values are to be converted to "HIGH School".

- JOB has a "" value. This needs to be replaced with NA.

- We will also create dummy variables for all the factors. 

- Please note that we will not be using INDEX variable as it serves as just an identifier for each row. And has no relationships to other variables.   

\
\

Making the above fixes to the data, we now have a "clean" dataset which can be explored further.
\

```{r}

#- some numeric variables like INCOME, HOME_VAL, BLUEBOOK, OLDCLAIM have been converted to Factor variables. This needs to be set right.

insure_train_full$INCOME <- as.numeric(insure_train_full$INCOME)
insure_train_full$HOME_VAL <- as.numeric(insure_train_full$HOME_VAL)
insure_train_full$BLUEBOOK <- as.numeric(insure_train_full$BLUEBOOK)
insure_train_full$OLDCLAIM <- as.numeric(insure_train_full$OLDCLAIM)

#- Some of the variables like MSTATUS, SEX, EDUCATION, JOB, CAR_TYPE, URBANICITY have some of the values encoded with "z_". Not that this will impact the analysis, but it will look a bit odd. So we will be fixing this.

#- EDUCATION has 2 "High School" values - one starting with "<" and another starting with "z_". It is assumed that both these values are to be converted to "HIGH School".

#- JOB has a "" value. This needs to be replaced with NA.

insure_train_full$MSTATUS <- as.factor(str_replace_all(insure_train_full$MSTATUS, "z_", ""))
insure_train_full$SEX <- as.factor(str_replace_all(insure_train_full$SEX, "z_", ""))
insure_train_full$EDUCATION <- as.factor(str_replace_all(insure_train_full$EDUCATION, "z_", ""))
insure_train_full$EDUCATION <- as.factor(str_replace_all(insure_train_full$EDUCATION, "<", ""))
insure_train_full$CAR_TYPE <- as.factor(str_replace_all(insure_train_full$CAR_TYPE, "z_", ""))
insure_train_full$URBANICITY <- as.factor(str_replace_all(insure_train_full$URBANICITY, "z_", ""))

insure_train_full$JOB[insure_train_full$JOB==""] <- NA
insure_train_full$JOB <- as.factor(str_replace_all(insure_train_full$JOB, "z_", ""))

#- We will also create dummy variables for all the factors and drop the original variables. 

dummy_vars<-as.data.frame(sapply(dummy(insure_train_full), FUN = as.numeric))
dummy_vars <- dummy_vars-1

insure_train_full <- cbind(select(insure_train_full, -PARENT1, -MSTATUS, -SEX, -EDUCATION, -JOB, -CAR_USE, -CAR_TYPE, -RED_CAR, -REVOKED, -URBANICITY), dummy_vars)

# insure_train_full <- cbind(insure_train_full, dummy_vars)

# - Please note that we will not be using INDEX variable as it serves as just an identifier for each row. And has no relationships to other variables.   

insure_train_full <- select(insure_train_full, -INDEX)

```



##1.2 Variable Relationships \

Since we have 2 models to build, we have 2 sets of assumptions to be checked:


- Logistic Regression for TARGET_FLAG: \newline
-- The dependent variable need not to be normally distributed \
-- Errors need to be independent but not normally distributed. \
-- We will be using GLM and GLM does not assume a linear relationship between dependent and independent variables. However, it assumes a linear relationship between link function and independent variables in logit model. \
-- Also does not use OLS (Ordinary Least Square) for parameter estimation. Instead, it uses maximum likelihood estimation (MLE) 

\
\


**NEED TO ADD SOME POINTS**

- Linear Regression for TARGET_AMT: \newline
-- The dependent variable is normally distributed \
-- Errors are independent and normally distributed. \


\
\



In next step below relationship between the target variable and dependent variables is shown in three charts.


##1.2 Data Summary Analysis


In this section, we will create summary data to better understand the relationship each of the variables have with our dependent variables using correlation, central tendency, and dispersion As shown in table 2.  

```{r, echo = FALSE, warning=FALSE, message=FALSE, results='hide'}

ds_stats <- psych::describe(insure_train_full, skew = TRUE, na.rm = TRUE)
#ds_stats
kable(ds_stats[1:7], caption= "Data Summary")
kable(ds_stats[8:13], caption= "Data Summary (Cont)")

fun1 <- function(a, y) cor(y, a , use = 'na.or.complete')
x<-insure_train_full[,]
Correlation_TARGET_FLAG <- sapply(x, FUN = fun1, y=insure_train_full$TARGET_FLAG) 

```


Now we will produce the correlation table between the independent variables and the dependent variables - TARGET_FLAG and TARGET_AMT  

\
\
First lets see the correlation for TARGET_FLAG:\

```{r, echo = FALSE, warning=FALSE, message=FALSE}
Correlation_TARGET_FLAG <- sort(Correlation_TARGET_FLAG, decreasing = TRUE)
kable(data.frame(Correlation_TARGET_FLAG), caption = "Correlation between TARGET_FLAG and predictor variables")

```
\

The above table suggests that none of the variables seem to have a very strong correlation with TARGET_FLAG. However, CAR_TYPE_Van, RED_CAR_no, JOB_Home.Maker, SEX_F, JOB_Clerical, CAR_TYPE_SUV, TRAVTIME, BLUEBOOK, CAR_TYPE_Pickup, CAR_TYPE_Sports.Car, JOB_Student, KIDSDRIV, JOB_Blue.Collar, HOMEKIDS, MSTATUS_No, EDUCATION_High.School, CAR_USE_Commercial, REVOKED_Yes, PARENT1_Yes, OLDCLAIM, CLM_FREQ, MVR_PTS and URBANICITY_Highly.Urban..Urban have a positive correlation. 
\
Similarly, URBANICITY_Highly.Rural..Rural, PARENT1_No, REVOKED_No, HOME_VAL, CAR_USE_Private, CAR_TYPE_Minivan, MSTATUS_Yes, JOB_Manager, AGE, CAR_AGE, TIF, EDUCATION_Masters, YOJ, EDUCATION_PhD, JOB_Lawyer, JOB_Doctor, EDUCATION_Bachelors, JOB_Professional, INCOME, SEX_M, RED_CAR_yes, CAR_TYPE_Panel.Truck have a negative correlation. 

\
\

Lets now see how values in some of the variable affects the correlation:

\

CAR_TYPE - If you drive Minivans and Panel Trucks you have lesser chance of being in a crash as against Pickups, Sports, SUVs and Vans. Since the distiction is clear, we believe that binning this variable accordingly will help strengthen the correlation.

\
\

EDUCATION - If you have only a high school education then you are more likely to crash than if you have a Bachelors, Masters or a Phd. Again binning this variable will strengthen the correlation.
\
\

JOB - If you are a Student, Homemaker, or in a Blue Collar or Clerical job, you are more likely to be in a crash against Doctor, Lawyer, Manager or professional.  Again binning this variable will strengthen the correlation.

\
\

We will carry out the above transformations in the Data Preparation phase.
\
\

Next lets look at the correlation for TARGET_AMT. 
\

Prior to this, we need to filter for only those records where there has been a crash. The amount incurred is relevant only when there is a crash. We then look at the correlations.
\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

insure_train_crash <- insure_train_full[insure_train_full$TARGET_FLAG==1,]
insure_train_crash <- select(insure_train_crash, -TARGET_FLAG)


#select(insure_train_full, -PARENT1, -MSTATUS, -SEX, -EDUCATION, -JOB, -CAR_USE, -CAR_TYPE, -RED_CAR, -REVOKED, -URBANICITY)
```

\

We will also have a look at the distribution of TARGET_AMT

```{r}

hist(insure_train_crash$TARGET_AMT)

```

\
We see from the above chart that the TARGET_AMT is not normally distributed.
\
Let's see if some transformations will make the situation better\

```{r}
show_charts <- function(x, plottype='hist', ...) {
    par(mfrow=c(2,3))
    xlabel <- unlist(str_split(deparse(substitute(x)), pattern = "\\$"))[2]
    ylabel <- unlist(str_split(deparse(substitute(y)), pattern = "\\$"))[2]
    
    if(plottype=='boxplot') {
        hist(x,main=xlabel)
        boxplot(x,main=xlabel)
    
        y<-log(x)
        boxplot(y,main='log transform')
        y<-sqrt(x)
        boxplot(y,main='sqrt transform')
        y<-sin(x)
        boxplot(y,main='sin transform')
        y<-(1/x)
        boxplot(y,main='Inverse transform')
    } 
    
    else if(plottype=='hist') {
        hist(x,main=xlabel)
        y<-log(x)
        hist(y,main='log transform')
        y<-sqrt(x)
        hist(y,main='sqrt transform')
        y<-sin(x)
        hist(y,main='sin transform')
        y<-(1/x)
        hist(y,main='Inverse transform')
    }
}

show_charts(insure_train_crash$TARGET_AMT, 'hist')


```

\
We can see from the above charts that a log transform and a sin transform on the TARGET_AMT will make it more normally distributed.
\
\

We now use this log transformed TARGET_AMT to check the correlations.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
Correlation_TARGET_AMT_log <- sapply(insure_train_crash, FUN = fun1, y=log(insure_train_crash$TARGET_AMT)) 

Correlation_TARGET_AMT_log <- sort(Correlation_TARGET_AMT_log, decreasing = TRUE)

kable(data.frame(Correlation_TARGET_AMT_log), caption = "Correlation between log transformed TARGET_AMT and predictor variables")

```
\
\

The above table suggests that none of the variables seem to have a very strong correlation with TARGET_AMT. However, JOB_Blue.Collar, JOB_Manager, OLDCLAIM, JOB_Doctor, JOB_Lawyer, REVOKED_No, URBANICITY_Highly.Urban..Urban, YOJ, CAR_AGE, AGE, JOB_Professional, CAR_TYPE_Van, PARENT1_Yes, EDUCATION_Masters, RED_CAR_yes, CAR_USE_Commercial, EDUCATION_PhD, MVR_PTS, SEX_M, MSTATUS_No, CAR_TYPE_Panel.Truck have a positive correlation. 
\
Similarly, MSTATUS_Yes, SEX_F, CAR_USE_Private, RED_CAR_no, JOB_Home.Maker, PARENT1_No, CAR_TYPE_Sports.Car, CAR_TYPE_SUV, EDUCATION_Bachelors, CLM_FREQ, EDUCATION_High.School, URBANICITY_Highly.Rural..Rural, JOB_Student, REVOKED_Yes, BLUEBOOK, CAR_TYPE_Minivan, KIDSDRIV, TIF, HOME_VAL, CAR_TYPE_Pickup, TRAVTIME, HOMEKIDS, INCOME, JOB_Clerical have a negative correlation. 

\
\

**NEED TO ANALYZE FURTHER**

\
\


\
\

Lets also use the sin transformed TARGET_AMT to check the correlations.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
Correlation_TARGET_AMT_sin <- sapply(insure_train_crash, FUN = fun1, y=sin(insure_train_crash$TARGET_AMT)) 

Correlation_TARGET_AMT_sin <- sort(Correlation_TARGET_AMT_sin, decreasing = TRUE)

kable(data.frame(Correlation_TARGET_AMT_sin), caption = "Correlation between sin transformed TARGET_AMT and predictor variables")

```
\
\

The above table suggests that none of the variables seem to have a very strong correlation with TARGET_AMT. However, INCOME, EDUCATION_Bachelors, JOB_Manager, EDUCATION_High.School, RED_CAR_yes, MSTATUS_No, JOB_Home.Maker, EDUCATION_PhD, TRAVTIME, JOB_Professional, URBANICITY_Highly.Urban..Urban, SEX_M, JOB_Blue.Collar, AGE, CAR_TYPE_Sports.Car, HOME_VAL, BLUEBOOK, PARENT1_No, CAR_USE_Commercial, REVOKED_No, CAR_TYPE_Panel.Truck have a positive correlation. 
\
Similarly, REVOKED_Yes, CAR_USE_Private, CAR_TYPE_SUV, PARENT1_Yes, KIDSDRIV, CAR_AGE, JOB_Clerical, HOMEKIDS, JOB_Doctor, CLM_FREQ, SEX_F, URBANICITY_Highly.Rural..Rural, MVR_PTS, EDUCATION_Masters, CAR_TYPE_Van, CAR_TYPE_Minivan, YOJ, TIF, MSTATUS_Yes, RED_CAR_no, JOB_Lawyer, CAR_TYPE_Pickup, JOB_Student, OLDCLAIM have a negative correlation. 

\
\

**NEED TO ANALYZE FURTHER**

\
\


##1.3	Outliers and Missing Values Identification


###1.3.1 Missing Values 

\
\
Based on the missing data from the below table, we can see that there are a few missing values for AGE, CAR_AGE, YOJ and JOB variables. 


```{r, echo = FALSE, warning=FALSE, message=FALSE}
missings<- sapply(insure_train_full,function(x) sum(is.na(x)))
kable(data.frame(missings), caption = "Missing Values")

```

\
\

We can try and impute values to AGE, YOJ, CAR_AGE. However, we will not be able to impute values for JOB since this is a categorical variable. Though there are a few methods to do this imputation, it may not be worth it.  
\
\
Lets see the impact if we have to exclude these missing records.
\
```{r}

sum(!complete.cases(insure_train_full))

# Percentage of records

sum(!complete.cases(insure_train_full))/nrow(insure_train_full) *100

```

\

We see from the above that excluding the missing rows will remove about 17.24% of the records. This would not seem to have too much of an impact. 
\
\
We will exclude the rows with the missing values when we do the data preparation / tranformations for the TARGET_FLAG dataset.

\
\

Similarly, based on the below analysis, we see that we are losing about 17.6% of the data for the TARGET_AMT dataset.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
missings<- sapply(insure_train_crash,function(x) sum(is.na(x)))
kable(data.frame(missings), caption = "Missing Values")
sum(!complete.cases(insure_train_crash))
# Percentage of records
sum(!complete.cases(insure_train_crash))/nrow(insure_train_crash) *100

```

\
\
We will exclude the rows with the missing values when we do the data preparation / tranformations for the TARGET_AMT dataset.

\
\


\

###1.3.2 Outliers identification 

In this section univariate analysis is being carried out and boxplots diagrams are being used to determine the outliers in variables and decide on whether to act on the outliers.\
\

We will do the outliers only on the numeric variables.\
\
Below are the plots:
\


```{r, echo = FALSE, warning=FALSE, message=FALSE}

#
mdata<- select(insure_train_full, KIDSDRIV, AGE, BLUEBOOK, CAR_AGE, CLM_FREQ, HOME_VAL, HOMEKIDS, INCOME, MVR_PTS, OLDCLAIM, TIF, TRAVTIME, YOJ)
mdata2 <- melt(mdata)
# Output the boxplot
p <- ggplot(data = mdata2, aes(x=variable, y=value)) + 
  geom_boxplot() + ggtitle("Outliers identification")
p + facet_wrap( ~ variable, scales="free", ncol=5)

```

From the "Outliers identification" plot above, we see that we have few outliers that we need to treat. \

We see that: KIDSDRIV, AGE, HOMEKIDS, MVR_PTS, OLDCLAIM, TIF, TRAVTIME, YOJ  need to be treated when we do the data preparation for modeling the TARGET_FLAG. 

\
\

We carry out the same exercise for TARGET_AMT as well:

\
\

We will do the outliers only on the numeric variables.\
\
Below are the plots:
\


```{r, echo = FALSE, warning=FALSE, message=FALSE}

#
mdata<- select(insure_train_crash, KIDSDRIV, AGE, BLUEBOOK, CAR_AGE, CLM_FREQ, HOME_VAL, HOMEKIDS, INCOME, MVR_PTS, OLDCLAIM, TIF, TRAVTIME, YOJ)
mdata2 <- melt(mdata)
# Output the boxplot
p <- ggplot(data = mdata2, aes(x=variable, y=value)) + 
  geom_boxplot() + ggtitle("Outliers identification")
p + facet_wrap( ~ variable, scales="free", ncol=5)

```

From the "Outliers identification" plot above, we see that we have few outliers that we need to treat. \

We see that: KIDSDRIV, AGE, MVR_PTS, TIF, TRAVTIME, YOJ  need to be treated when we do the data preparation for modeling the TARGET_AMT. 


\newpage

##1.3.3 Analysis the link function \

In this section, we will investigate how our initial data aligns with a typical logistic model plot. 

Recall the Logistic Regression is part of a larger class of algorithms known as Generalized Linear Model (glm).  The fundamental equation of generalized linear model is:

$g(E(y)) = a+ Bx_1+B_2x_2+ B_3x_3+...$   

where, g() is the link function, E(y) is the expectation of target variable and $B_0 + B_1x_1 + B_2x_2+B_3x_3$ is the linear predictor ( $B_0,B_1,B_2, B_3$ to be predicted). The role of link function is to 'link' the expectation of y to linear predictor.

In logistic regression, we are only concerned about the probability of outcome dependent variable ( success or failure). As described above, g() is the link function. This function is established using two things: Probability of Success (p) and Probability of Failure (1-p).  p should meet following criteria:
It must always be positive (since p >= 0)
It must always be less than equals to 1 (since p <= 1).

Now let's investigate how our initial data model aligns with the above criteria. In other words, we will plot regression model plots for each variable and compare it to a typical logistic model plot:


```{r}
par(mfrow=c(2,3))

# #fun1 <- function(a, y) cor(y, a , use = 'na.or.complete')
# #Correlation_TARGET_FLAG <- sapply(x, FUN = fun1, y=insure_train_full$TARGET_FLAG) 
# 
# show_chart_logi.hist <- function(a, y, ...) {
# #    xlabel <- unlist(str_split(deparse(substitute(a)), pattern = "\\$"))[2]
#     xlabel <- deparse(substitute(a))
#     message(xlabel)
#     logi.hist.plot(a,y,logi.mod = 1, type="hist", boxp=FALSE,col="gray", mainlabel = xlabel)
# }

x <- insure_train_full[,-2]
x <- x[complete.cases(x),]

# sapply(x, FUN = show_chart_logi.hist, y=x$TARGET_FLAG) 

logi.hist.plot(x$REVOKED_Yes,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'REVOKED_Yes')
logi.hist.plot(x$CAR_USE_Private,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_USE_Private')
logi.hist.plot(x$CAR_TYPE_SUV,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_TYPE_SUV')
logi.hist.plot(x$PARENT1_Yes,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'PARENT1_Yes')
logi.hist.plot(x$KIDSDRIV,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'KIDSDRIV')
logi.hist.plot(x$CAR_AGE,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_AGE')
logi.hist.plot(x$JOB_Clerical,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Clerical')
logi.hist.plot(x$HOMEKIDS,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'HOMEKIDS')
logi.hist.plot(x$JOB_Doctor,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Doctor')
logi.hist.plot(x$CLM_FREQ,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CLM_FREQ')
logi.hist.plot(x$SEX_F,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'SEX_F')
logi.hist.plot(x$URBANICITY_Highly.Rural..Rural,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'URBANICITY_Highly.Rural..Rural')
logi.hist.plot(x$MVR_PTS,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'MVR_PTS')
logi.hist.plot(x$EDUCATION_Masters,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'EDUCATION_Masters')
logi.hist.plot(x$CAR_TYPE_Van,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_TYPE_Van')
logi.hist.plot(x$CAR_TYPE_Minivan,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_TYPE_Minivan')
logi.hist.plot(x$YOJ,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'YOJ')
logi.hist.plot(x$TIF,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'TIF')
logi.hist.plot(x$MSTATUS_Yes,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'MSTATUS_Yes')
logi.hist.plot(x$RED_CAR_no,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'RED_CAR_no')
logi.hist.plot(x$JOB_Lawyer,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Lawyer')
logi.hist.plot(x$CAR_TYPE_Pickup,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_TYPE_Pickup')
logi.hist.plot(x$JOB_Student,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Student')
logi.hist.plot(x$OLDCLAIM,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'OLDCLAIM')
logi.hist.plot(x$INCOME,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'INCOME')
logi.hist.plot(x$EDUCATION_Bachelors,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'EDUCATION_Bachelors')
logi.hist.plot(x$JOB_Manager,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Manager')
logi.hist.plot(x$EDUCATION_High.School,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'EDUCATION_High.School')
logi.hist.plot(x$RED_CAR_yes,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'RED_CAR_yes')
logi.hist.plot(x$MSTATUS_No,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'MSTATUS_No')
logi.hist.plot(x$JOB_Home.Maker,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Home.Maker')
logi.hist.plot(x$EDUCATION_PhD,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'EDUCATION_PhD')
logi.hist.plot(x$TRAVTIME,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'TRAVTIME')
logi.hist.plot(x$JOB_Professional,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Professional')
logi.hist.plot(x$URBANICITY_Highly.Urban..Urban,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'URBANICITY_Highly.Urban..Urban')
logi.hist.plot(x$SEX_M,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'SEX_M')
logi.hist.plot(x$JOB_Blue.Collar,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'JOB_Blue.Collar')
logi.hist.plot(x$AGE,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'AGE')
logi.hist.plot(x$CAR_TYPE_Sports.Car,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_TYPE_Sports.Car')
logi.hist.plot(x$HOME_VAL,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'HOME_VAL')
logi.hist.plot(x$BLUEBOOK,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'BLUEBOOK')
logi.hist.plot(x$PARENT1_No,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'PARENT1_No')
logi.hist.plot(x$CAR_USE_Commercial,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_USE_Commercial')
logi.hist.plot(x$REVOKED_No,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'REVOKED_No')
logi.hist.plot(x$CAR_TYPE_Panel.Truck,x$TARGET_FLAG,logi.mod = 1, type='hist', boxp=FALSE,col='gray', mainlabel = 'CAR_TYPE_Panel.Truck')

```

##Interpretation \


**NOT SEEING ANY CLEAR TRENDS. DO WE NEED TO INCLUDE THIS SECTION?**

**IF SO, NEED TO REVISE THE BELOW TEXT**

You can see clearly that the probability of crime being above average increases as we get closer to the "1" classification for the indus,nox,age,rad,tax,and lstat  variables. In the middle, the probability changes at the highest rate, while it tails off at each end in order to bound it between 0 and 1. \

You can see clearly that the probability of crime being above average decreases as we get closer to the "1" classification for the zn, dis,black, and mdev  variables. In the middle, the probability changes at the lowest rate. However, it does not tails off at each end for all of the variables.

\
\
\


#2. Data Preparation 

Now that we have completed the data exploration / analysis, we will be cleaning and consolidating data into two datasets for use in analysis and modeling. \

\
One dataset will be used for building and selecting models for TARGET_FLAG and the other dataset with only the "crash" records will be used for building and selecting models for TARGET_AMT.\
\


We will be following the below steps as guidelines: \
- Outliers treatment \
- Missing values treatment \
- Adding New Variables \



##2.1 Outliers treatment

For outliers, we will create 3 sets of variables. 

- The first set uses the capping method. In this method, we will replace all outliers that lie outside the 1.5 times of IQR limits. We will cap it by replacing those observations less than the lower limit with the value of 5th %ile and those that lie above the upper limit with the value of 95th %ile. 

- In the second set, we will use the log transformation and create the respective variables

- In the third set, we will use the sin transformation and create the respective variables

\
\

We do the above set of variables for both the TARGET_FLAG dataset as well as the TARGET_AMT dataset.
\
\
###2.1.1 Outliers treatment for Full Dataset (TARGET_FLAG)

\
We create new variables for KIDSDRIV, AGE, HOMEKIDS, MVR_PTS, OLDCLAIM, TIF, TRAVTIME and YOJ by capping the outlier values. 

\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

treat_outliers <- function(x) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
caps <- quantile(x, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]
 
return(x)
}

#KIDSDRIV, AGE, HOMEKIDS, MVR_PTS, OLDCLAIM, TIF, TRAVTIME and YOJ

insure_train_full$KIDSDRIV_cap <- treat_outliers(insure_train_full$KIDSDRIV)
insure_train_full$AGE_cap <- treat_outliers(insure_train_full$AGE)
insure_train_full$HOMEKIDS_cap <- treat_outliers(insure_train_full$HOMEKIDS)
insure_train_full$MVR_PTS_cap <- treat_outliers(insure_train_full$MVR_PTS)
insure_train_full$OLDCLAIM_cap <- treat_outliers(insure_train_full$OLDCLAIM)
insure_train_full$TIF_cap <- treat_outliers(insure_train_full$TIF)
insure_train_full$TRAVTIME_cap <- treat_outliers(insure_train_full$TRAVTIME)
insure_train_full$YOJ_cap <- treat_outliers(insure_train_full$YOJ)


```

Lets see how the capped variables look in boxplots.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

par(mfrow=c(1,3))

boxplot(insure_train_full$KIDSDRIV_cap,main="KIDSDRIV_cap")
boxplot(insure_train_full$AGE_cap,main="AGE_cap")
boxplot(insure_train_full$HOMEKIDS_cap,main="HOMEKIDS_cap")
boxplot(insure_train_full$MVR_PTS_cap,main="MVR_PTS_cap")
boxplot(insure_train_full$OLDCLAIM_cap,main="OLDCLAIM_cap")
boxplot(insure_train_full$TIF_cap,main="TIF_cap")
boxplot(insure_train_full$TRAVTIME_cap,main="TRAVTIME_cap")
boxplot(insure_train_full$YOJ_cap,main="YOJ_cap")


```
\
\

In the second set, we will use the log transformation and create new variables for KIDSDRIV, AGE, HOMEKIDS, MVR_PTS, OLDCLAIM, TIF, TRAVTIME and YOJ. 

\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

insure_train_full$KIDSDRIV_log <- log(insure_train_full$KIDSDRIV)
insure_train_full$AGE_log <- log(insure_train_full$AGE)
insure_train_full$HOMEKIDS_log <- log(insure_train_full$HOMEKIDS)
insure_train_full$MVR_PTS_log <- log(insure_train_full$MVR_PTS)
insure_train_full$OLDCLAIM_log <- log(insure_train_full$OLDCLAIM)
insure_train_full$TIF_log <- log(insure_train_full$TIF)
insure_train_full$TRAVTIME_log <- log(insure_train_full$TRAVTIME)
insure_train_full$YOJ_log <- log(insure_train_full$YOJ)


```


Lets see how the log transformed variables look in boxplots.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

par(mfrow=c(1,3))

boxplot(insure_train_full$KIDSDRIV_log,main="KIDSDRIV_log")
boxplot(insure_train_full$AGE_log,main="AGE_log")
boxplot(insure_train_full$HOMEKIDS_log,main="HOMEKIDS_log")
boxplot(insure_train_full$MVR_PTS_log,main="MVR_PTS_log")
boxplot(insure_train_full$OLDCLAIM_log,main="OLDCLAIM_log")
boxplot(insure_train_full$TIF_log,main="TIF_log")
boxplot(insure_train_full$TRAVTIME_log,main="TRAVTIME_log")
boxplot(insure_train_full$YOJ_log,main="YOJ_log")


```


\
\

In the third set, we will use the sin transformation and create new variables for KIDSDRIV, AGE, HOMEKIDS, MVR_PTS, OLDCLAIM, TIF, TRAVTIME and YOJ. 

\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

insure_train_full$KIDSDRIV_sin <- sin(insure_train_full$KIDSDRIV)
insure_train_full$AGE_sin <- sin(insure_train_full$AGE)
insure_train_full$HOMEKIDS_sin <- sin(insure_train_full$HOMEKIDS)
insure_train_full$MVR_PTS_sin <- sin(insure_train_full$MVR_PTS)
insure_train_full$OLDCLAIM_sin <- sin(insure_train_full$OLDCLAIM)
insure_train_full$TIF_sin <- sin(insure_train_full$TIF)
insure_train_full$TRAVTIME_sin <- sin(insure_train_full$TRAVTIME)
insure_train_full$YOJ_sin <- sin(insure_train_full$YOJ)


```


Lets see how the sin transformed variables look in boxplots.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

par(mfrow=c(1,3))

boxplot(insure_train_full$KIDSDRIV_sin,main="KIDSDRIV_sin")
boxplot(insure_train_full$AGE_sin,main="AGE_sin")
boxplot(insure_train_full$HOMEKIDS_sin,main="HOMEKIDS_sin")
boxplot(insure_train_full$MVR_PTS_sin,main="MVR_PTS_sin")
boxplot(insure_train_full$OLDCLAIM_sin,main="OLDCLAIM_sin")
boxplot(insure_train_full$TIF_sin,main="TIF_sin")
boxplot(insure_train_full$TRAVTIME_sin,main="TRAVTIME_sin")
boxplot(insure_train_full$YOJ_sin,main="YOJ_sin")

```


###2.1.2 Outliers treatment for "crashed" Dataset (TARGET_AMT)


\
We create new variables for KIDSDRIV, AGE, MVR_PTS, TIF, TRAVTIME and YOJ by capping the outlier values. 

\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

treat_outliers <- function(x) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
caps <- quantile(x, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]
 
return(x)
}

#KIDSDRIV, AGE, MVR_PTS, TIF, TRAVTIME and YOJ

insure_train_crash$KIDSDRIV_cap <- treat_outliers(insure_train_crash$KIDSDRIV)
insure_train_crash$AGE_cap <- treat_outliers(insure_train_crash$AGE)
insure_train_crash$MVR_PTS_cap <- treat_outliers(insure_train_crash$MVR_PTS)
insure_train_crash$TIF_cap <- treat_outliers(insure_train_crash$TIF)
insure_train_crash$TRAVTIME_cap <- treat_outliers(insure_train_crash$TRAVTIME)
insure_train_crash$YOJ_cap <- treat_outliers(insure_train_crash$YOJ)


```

Lets see how the capped variables look in boxplots.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

par(mfrow=c(1,3))

boxplot(insure_train_crash$KIDSDRIV_cap,main="KIDSDRIV_cap")
boxplot(insure_train_crash$AGE_cap,main="AGE_cap")
boxplot(insure_train_crash$MVR_PTS_cap,main="MVR_PTS_cap")
boxplot(insure_train_crash$TIF_cap,main="TIF_cap")
boxplot(insure_train_crash$TRAVTIME_cap,main="TRAVTIME_cap")
boxplot(insure_train_crash$YOJ_cap,main="YOJ_cap")


```
\
\

In the second set, we will use the log transformation and create new variables for KIDSDRIV, AGE, HOMEKIDS, MVR_PTS, OLDCLAIM, TIF, TRAVTIME and YOJ. 

\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

insure_train_crash$KIDSDRIV_log <- log(insure_train_crash$KIDSDRIV)
insure_train_crash$AGE_log <- log(insure_train_crash$AGE)
insure_train_crash$MVR_PTS_log <- log(insure_train_crash$MVR_PTS)
insure_train_crash$TIF_log <- log(insure_train_crash$TIF)
insure_train_crash$TRAVTIME_log <- log(insure_train_crash$TRAVTIME)
insure_train_crash$YOJ_log <- log(insure_train_crash$YOJ)


```


Lets see how the log transformed variables look in boxplots.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

par(mfrow=c(1,3))

boxplot(insure_train_crash$KIDSDRIV_log,main="KIDSDRIV_log")
boxplot(insure_train_crash$AGE_log,main="AGE_log")
boxplot(insure_train_crash$MVR_PTS_log,main="MVR_PTS_log")
boxplot(insure_train_crash$TIF_log,main="TIF_log")
boxplot(insure_train_crash$TRAVTIME_log,main="TRAVTIME_log")
boxplot(insure_train_crash$YOJ_log,main="YOJ_log")


```


\
\

In the third set, we will use the sin transformation and create new variables for KIDSDRIV, AGE, HOMEKIDS, MVR_PTS, OLDCLAIM, TIF, TRAVTIME and YOJ. 

\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

insure_train_crash$KIDSDRIV_sin <- sin(insure_train_crash$KIDSDRIV)
insure_train_crash$AGE_sin <- sin(insure_train_crash$AGE)
insure_train_crash$MVR_PTS_sin <- sin(insure_train_crash$MVR_PTS)
insure_train_crash$TIF_sin <- sin(insure_train_crash$TIF)
insure_train_crash$TRAVTIME_sin <- sin(insure_train_crash$TRAVTIME)
insure_train_crash$YOJ_sin <- sin(insure_train_crash$YOJ)


```


Lets see how the sin transformed variables look in boxplots.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

par(mfrow=c(1,3))

boxplot(insure_train_crash$KIDSDRIV_sin,main="KIDSDRIV_sin")
boxplot(insure_train_crash$AGE_sin,main="AGE_sin")
boxplot(insure_train_crash$MVR_PTS_sin,main="MVR_PTS_sin")
boxplot(insure_train_crash$TIF_sin,main="TIF_sin")
boxplot(insure_train_crash$TRAVTIME_sin,main="TRAVTIME_sin")
boxplot(insure_train_crash$YOJ_sin,main="YOJ_sin")

```


##2.2 Missing Values treatment

\
\
As we have seen in the data exploration phase, we can do with removing the rows that contain missing values. We now do this for both the datasets:

\
\

```{r}

insure_train_full <- insure_train_full[complete.cases(insure_train_full),]
insure_train_crash <- insure_train_crash[complete.cases(insure_train_crash),]

```


\
\

##2.3 Adding New Variables

In this section, we generate some additional variables that we feel will help the correlations. As before, we do it for both the datasets.

###2.3.1 New Variables for Full Dataset (TARGET_FLAG)

\

The following were some of the observations we made during the data exploration phase for TARGET_FLAG

\
\

CAR_TYPE - If you drive Minivans and Panel Trucks you have lesser chance of being in a crash as against Pickups, Sports, SUVs and Vans. Since the distiction is clear, we believe that binning this variable accordingly will help strengthen the correlation. \
\
Accordingly, we will bin these variables as below:
\
CAR_TYPE_FLAG_BIN : \
\
- 1 : if CAR_TYPE is Minivans or Panel Trucks \
- 0 : if CAR_TYPE is Pickups, Sports, SUVs or Vans
\
\


```{r}

insure_train_full$CAR_TYPE_FLAG_BIN <- ifelse(insure_train_full$CAR_TYPE_Minivan | insure_train_full$CAR_TYPE_Panel.Truck, 1, 0)

```

\
\

EDUCATION - If you have only a high school education then you are more likely to crash than if you have a Bachelors, Masters or a Phd. Again binning this variable will strengthen the correlation.
\
\
Accordingly, we will bin these variables as below:
\
EDUCATION_FLAG_BIN : \
\
- 1 : if EDUCATION is High School \
- 0 : if EDUCATION is Bachelors, Masters or Phd
\
\


```{r}

insure_train_full$EDUCATION_FLAG_BIN <- ifelse(insure_train_full$EDUCATION_High.School, 1, 0)

```



JOB - If you are a Student, Homemaker, or in a Blue Collar or Clerical job, you are more likely to be in a crash against Doctor, Lawyer, Manager or professional.  Again binning this variable will strengthen the correlation.

\
\
Accordingly, we will bin these variables as below:
\
JOB_TYPE_FLAG_BIN : \
\
- 1 : if JOB_TYPE is Student, Homemaker, or in a Blue Collar or Clerical \
- 0 : if JOB_TYPE is Doctor, Lawyer, Manager or professional
\
\

```{r}

insure_train_full$JOB_TYPE_FLAG_BIN <- ifelse(insure_train_full$JOB_Student |  insure_train_full$JOB_Home.Maker | insure_train_full$JOB_Clerical | insure_train_full$JOB_Blue.Collar, 1, 0)

```



