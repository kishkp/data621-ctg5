---
title: "How to do Effective and Sucessful Bank Telemarketing "
shorttitle: "Predictive Modeling with Losgistic Regression "
author: 
  - name: Arindam Barman
    affiliation: "1"
    corresponding: no    # Define only one corresponding author
    address: New York, NY
    email: my@email.com
  - name: Mohamed Elmoudni
    affiliation: "1"
  - name: Shazia Khan
    affiliation: "1"
  - name: Kishore Prasad
    affiliation: "1"
affiliation:
  - id: 1
    institution: City University of New York (CUNY)

abstract: |
   use 250 words or less to summarize your problem, methodology, and major outcomes. Even though direct marketing is a standard method for banks to utilize in the face of competition and financial unstability, it has, however, been shown to exhibit poor performance. The telemarketing calls are simply not answered or answered and immediately disconnected. It is however welcomed by the right person who is in need of financial relief. The aim of this exercise is to target clients more effectively and efficiently based on the data from a Portuguese bank telemarketing effort.
   We first used logistic regression to predict the binary response variable. 
   The outcomes....
  
  
keywords: "select a few key words (up to five) related to your work....logistic regression model, linear discriminant analysis (LDA), predictive modeling, bank telemarketing, direct marketing, Data Mining"


class: man
lang: english
figsintext: no
lineno: yes
bibliography:
  - r-references.bib

output: papaja::apa6_pdf
---

```{r message = FALSE, warning = FALSE}
library("papaja")
apa_prepare_doc() # Prepare document for rendering
```


# Introduction
  describe the background and motivation of your problem--
  
  After looking at various options, we settled for this project for our final since it met all the requirements.
  
  "Regression analysis is one of the most commonly used statistical techniques in social and behavioral sciences as well as in physical sciences. Its main objective is to explore the relationship between a dependent variable and one or more independent variables (which are also called predictor or explanatory variables)." This is the definition provided by www.unesco.org for Regression Analysis
  
  The most successful direct marketing is to predict the customers that have a higher probability to do business. Data exploration technique, is crucial to understand customer behavior. Many banks and services are moving to adopt the predictive technique based on the data mining to predict the customer profile before targeting them. The prediction or classification is the most important task in the data exploration and model building that is usually applied to classify the group of data. In classification, the outcome is a categorical variable and several combinations of input variable are used to build a model and the model that gives a better prediction with the best accuracy is chosen to target the prospective customers.
  
  The data set contains approximately 41188 obs. of 21 variables. \

This dataset is based on "Bank Marketing" UCI dataset (please check the description at: http://archive.ics.uci.edu/ml/datasets/Bank+Marketing).
   The data is enriched by the addition of five new social and economic features/attributes (national wide indicators from a ~10M population country), published by the Banco de Portugal and publicly available at: https://www.bportugal.pt/estatisticasweb.\
   
The binary classification goal is to predict if the client will subscribe a bank term deposit (variable y).

This dependent variable tells whether the client will subscribe a bank term deposit or not. This is a binary variable and as such we will be using a Logistic Regression Model.


# Literature Review
  discuss how other researchers have addressed similar problems, what their achievements are, and what the advantage and drawbacks of each reviewed approach are.  Explain how your investigation is similar or different to the state-of-the-art.  Please do not discuss paper one at a time, instead, identify key characteristics of your topic, and discuss them in a whole. Please cite the relevant papers where appropriate.  
  
  We will be reviewing three papers addresseing the same problem of bank  telemarketing.\
  
  1. http://bru-unide.iscte.pt/RePEc/pdfs/13-06.pdf \
  2. http://www.ijmbs.com/Vol6/1/4-vaidehi-r.pdf \
  3. http://www.columbia.edu/~jc4133/ADA-Project.pdf \
  
  
# Methodology
  discuss the key aspects of your problem, data set and regression model(s). Given that you are working on real-world data, explain at a high-level your exploratory data analysis, how you prepared the data for regression modeling, your process for building regression models, and your model selection. . <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->
  
  The data is available on website for UC Irvine Machine Learning Repository. There are two different data sets available. The "bank" data has 45,211 records with 16 attributes and 1 response variable. The "bank-additional" data has 41,188 records with additional attributes added to "bank" data, it has 20 attributes and 1 response variable. We chose to use the data with additional attributes.
  
  The data consists of four groups of information.\
  - Client's personal infomation \
  - Client's bank information \
  - Bank's telemarketing campaign information \
  - Social and economic information \
  
  The main problem with the dataset is that it consists of many missing values which are labeled "Unknown". The missing data consists of 26% of the data. We decided to retain the missing data to help with our regression modeling. The other problem with the data is that only 12% of the data shows the response variable to be "y".
  
  We looked at each varable and the unique values contained in each variable and what they represented. Wecan divide the variables in the follwing three categories:\
  
  1 - Binary values of "yes" and "no" wit null values given as "unknown". \
  2 - Categorical values with "unknown" as missing values. The categorical variable require dummy variables to be created for each unique value. We included "unknown" as one of the dummy variable. \
  3 - numeric values with "999" as indication of null value. We created a variable to indicate if the data was missing or present.
  

# Experimentation and Results
  describe the specifics of what you did (data exploration, data preparation, model building, selection, evalutation) and what you found out (statistical analysis, inter pretation and discussion of the results)
   
## Data Exploration

  In section we will explore and gain some insights into the dataset by pursuing the below high level steps and inquiries: \
-Variable identification \
-Missing values and Unique Values \
-Variables relationship to y

```{r, echo = FALSE, warning=FALSE, message=FALSE}
if (!require("ggplot2",character.only = TRUE)) (install.packages("ggplot2",dep=TRUE))
if (!require("MASS",character.only = TRUE)) (install.packages("MASS",dep=TRUE))
if (!require("knitr",character.only = TRUE)) (install.packages("knitr",dep=TRUE))
if (!require("xtable",character.only = TRUE)) (install.packages("xtable",dep=TRUE))
if (!require("dplyr",character.only = TRUE)) (install.packages("dplyr",dep=TRUE))
if (!require("psych",character.only = TRUE)) (install.packages("psych",dep=TRUE))
if (!require("stringr",character.only = TRUE)) (install.packages("stringr",dep=TRUE))
#if (!require("car",character.only = TRUE)) (install.packages("car",dep=TRUE))
if (!require("faraway",character.only = TRUE)) (install.packages("faraway",dep=TRUE))
if (!require("popbio",character.only = TRUE)) (install.packages("popbio",dep=TRUE))
if (!require("gdata",character.only = TRUE)) (install.packages("gdata",dep=TRUE))
if (!require("reshape",character.only = TRUE)) (install.packages("reshape",dep=TRUE))


#install.packages("fancyvrb")

library(ggplot2)
library(MASS)
library(knitr)
library(xtable)
library(dplyr)
library(psych)
library(stringr)
#library(car)
library(faraway)
library(aod)
library(Rcpp)
library(leaps)
library(ISLR)
library(AUC)
library(ROCR)
library(Amelia)
library(popbio)
library(gdata)
library(reshape)
library(gridExtra)

bank_train <- read.table(
  "https://raw.githubusercontent.com/kishkp/data621-ctg5/master/Final%20Project/bank-additional-full.csv",
           sep = ";",
           header = TRUE)

variables<- read.csv(
  "https://raw.githubusercontent.com/kishkp/data621-ctg5/master/Final%20Project/Variable%20Description.csv")
kable(variables, caption = "Variable Description", padding = 0) 


bank_test <-read.table(
  "https://raw.githubusercontent.com/kishkp/data621-ctg5/master/Final%20Project/bank-additional.csv",
           sep = ";",
           header = TRUE)
```
  
  We notice that the variables are numerical, categorical and binary. The responce variable y is binary.

Based on the original dataset, our predictor input has 21 variables. And our response variable is 1 variable called y, binomial logistic regression is the most appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more metric (interval or ratio scale) independent variables.

Table 2 shows us that there are no missing values per say, since they are all have the values of either "unknown" or "999" in our dataset as shown in table 2 and graph format.\

```{r, echo = FALSE, warning=FALSE, message=FALSE}

#finding missing values
missings<- data.frame(sapply(bank_train,function(x) sum(is.na(x))))
names(missings)[1]<- paste("Missing Values")
kable(missings, caption = "Missing Values")

```



```{r, echo = FALSE, warning=FALSE, message=FALSE}
# missing values graph
#missmap(bank_train, main = "Missing values vs observed")

### finding unique values
uniques<- data.frame(sapply(bank_train, function(x) length(unique(x))))
names(uniques)[1]<- paste("Unique Values")
kable(uniques, caption = "Unique Values")
```


```{r, echo = FALSE, warning=FALSE, message=FALSE}

#exploratory graphs

par(mfrow=c(1,1))
#round(prop.table(table(bank_train$y, bank_train$age),2)*100,2)  #student, retired
p1 <- ggplot(bank_train, aes(age)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$job),2)*100,2)  #student, retired
p2 <- ggplot(bank_train, aes(job)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$marital),2)*100,2) #unknown
p3 <- ggplot(bank_train, aes(marital)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$education),2)*100,2) #illeterate
p4 <- ggplot(bank_train, aes(education)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$default),2)*100,2) #no
p5<- ggplot(bank_train, aes(default)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$housing),2)*100,2) #no
p6<- ggplot(bank_train, aes(housing)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$loan),2)*100,2) #no
p7<- ggplot(bank_train, aes(loan)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$contact),2)*100,2) #cellular
p8 <- ggplot(bank_train, aes(contact)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$month),2)*100,2) #march, dec, sep, oct
p9 <- ggplot(bank_train, aes(month)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$day_of_week),2)*100,2) #Thursday
p10 <- ggplot(bank_train, aes(day_of_week)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$duration),2)*100,2) #increases with every contact upto 5
p11 <- ggplot(bank_train, aes(duration)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))+ xlim(0, 2200)

#round(prop.table(table(bank_train$y, bank_train$campaign),2)*100,2) #increases with every contact upto 5
p12 <- ggplot(bank_train, aes(campaign)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$pdays),2)*100,2) #increases with every contact upto 5
p13 <- ggplot(bank_train, aes(pdays)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

#round(prop.table(table(bank_train$y, bank_train$previous),2)*100,2) #increases with every contact upto 5
p14 <- ggplot(bank_train, aes(previous)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

  #round(prop.table(table(bank_train$y, bank_train$poutcome),2)*100,2) #success
p15 <- ggplot(bank_train, aes(poutcome)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

 #round(prop.table(table(bank_train$y, bank_train$emp.var.rate),2)*100,2) #success
p16 <- ggplot(bank_train, aes(emp.var.rate)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

 #round(prop.table(table(bank_train$y, bank_train$cons.price.idx),2)*100,2) #success
p17 <- ggplot(bank_train, aes(cons.price.idx)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

 #round(prop.table(table(bank_train$y, bank_train$cons.conf.idx),2)*100,2) #success
p18 <- ggplot(bank_train, aes(cons.conf.idx)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

 #round(prop.table(table(bank_train$y, bank_train$euribor3m),2)*100,2) #success
p19 <- ggplot(bank_train, aes(euribor3m)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))

 #round(prop.table(table(bank_train$y, bank_train$nr.employed),2)*100,2) #success
p20 <-ggplot(bank_train, aes(nr.employed)) + geom_bar(aes(fill = y), position = "fill")+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))


 
#--------------------Multiplot funcion----------------------------------------------

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    #grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
#-----------------------------------------------------------

multiplot(p1, p2, p3, p4, cols=2)
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}

multiplot(p5, p6, p7, p8, cols=2)

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}

multiplot(p9, p10, p11, p12, cols=2)

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}

multiplot(p13, p14, p15, p16, cols=2)

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}

multiplot(p17, p18, p19, p20, cols=2)

```


Table 4 shows the analysis of variables after data exploration.


```{r, echo = FALSE, warning=FALSE, message=FALSE}

# This is table 4

variables<- read.csv(
  "https://raw.githubusercontent.com/kishkp/data621-ctg5/master/Final%20Project/Variable%20Analysis.csv")
kable(variables, caption = "Variable Description", padding = 0) 

```

   
## Data Preparation

-Convert Binary to 0 and 1\
-Create dummy variables\
-Data Summary Analysis \
-Correlation of Variables with y

### Convert to Binary

Now in order to prepare the data for modeling, we need to update Yes = 1 and No = 0. \

```{r, echo = FALSE, warning=FALSE, message=FALSE}

bank_train2<-bank_train

#update response variable to binary values of 0 and 1
levels(bank_train2$y) <- c(0, 1)
bank_train2$y <- as.numeric(levels(bank_train2$y))[bank_train2$y]

```

### Create dummy variables

Now we need to create dummy variables to find out the relationship between y variables and dependent variables, for all categorical variables.\
```{r, echo = FALSE, warning=FALSE, message=FALSE}

# age is numeric 

#create dummy variables for job values
for(level in unique(bank_train2$job)){
  bank_train2[paste("job", level, sep = "_")] <- ifelse(bank_train2$job == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$job <- NULL
#head(bank_train2)

#create dummy variables for marital values
#levels(bank_train2$marital)
for(level in unique(bank_train2$marital)){
  bank_train2[paste("marital", level, sep = "_")] <- ifelse(bank_train2$marital == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$marital <- NULL
#head(bank_train2)

#--------------------------------------------------------------------------
#education dummy variables primary, secondary tertiary, unknown and illiterate

#education_None
bank_train2$education_illiterate <- as.numeric(ifelse(bank_train2$education == "illiterate", 1, 0))
#table(bank_train2$education_Illiterate)

#education_Unknown
bank_train2$education_unknown <-as.numeric(ifelse(bank_train2$education == "unknown", 1, 0))
#table(bank_train2$education_Unknown)

#education_Primary
bank_train2$education_primary <- as.numeric(ifelse(bank_train2$education == "basic.4y" 
                                        | bank_train2$education == "basic.6y", 1, 0))
#table(bank_train2$education_Primary)

#education_Secondary
bank_train2$education_secondary <- as.numeric(ifelse(bank_train2$education == "basic.9y" 
                                        | bank_train2$education == "high.school", 1, 0))
#table(bank_train2$education_Secondary)

#education_Tertiary
bank_train2$education_tertiary <- as.numeric(ifelse(bank_train2$education == "professional.course" 
                                        | bank_train2$education == "university.degree", 1, 0))
#table(bank_train2$education_Tertiary)

#Delete original catagorical variable
bank_train2$education <- NULL
#---------------------------------------------------

# contact has 2 levels - 1 variable is required
#levels(bank_train2$default)
for(level in unique(bank_train2$default)){
  bank_train2[paste("default", level, sep = "_")] <- ifelse(bank_train2$default == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$default <- NULL


#levels(bank_train2$housing)
for(level in unique(bank_train2$housing)){
  bank_train2[paste("housing", level, sep = "_")] <- ifelse(bank_train2$housing == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$housing <- NULL

#levels(bank_train2$loan)
for(level in unique(bank_train2$loan)){
  bank_train2[paste("loan", level, sep = "_")] <- ifelse(bank_train2$loan == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$loan <- NULL

# contact has 2 levels - 1 variable is required
#levels(bank_train2$contact)
for(level in unique(bank_train2$contact)){
  bank_train2[paste("contact", level, sep = "_")] <- ifelse(bank_train2$contact == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$contact <- NULL

#levels(bank_train2$month)
for(level in unique(bank_train2$month)){
  bank_train2[paste("month", level, sep = "_")] <- ifelse(bank_train2$month == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$month <- NULL

#levels(bank_train2$day_of_week)
for(level in unique(bank_train2$day_of_week)){
  bank_train2[paste("day_of_week", level, sep = "_")] <- ifelse(bank_train2$day_of_week == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$day_of_week <- NULL

#duration is numeric
#campaign is numeric

#pdays is numeric
#dummy variable for pdays -previous contact yes or no ; 1 or 0  when 999
bank_train2$previous_contact <- as.numeric(ifelse(bank_train2$pdays == 999, 0, 1))

#previous is numeric

#levels(bank_train2$poutcome)
for(level in unique(bank_train2$poutcome)){
  bank_train2[paste("poutcome", level, sep = "_")] <- ifelse(bank_train2$poutcome == level, 1, 0)
}
#Delete original catagorical variable
bank_train2$poutcome <- NULL

# emp.var.rate is numeric
# cons.price.idx is numeric
# cons.conf.idx  is numeric
# euribor3m is numeric
# nr.employed is numeric


```

### Data Summary Analysis 

```{r, echo = FALSE, warning=FALSE, message=FALSE}

#str(bank_train2)

ds_stats <- psych::describe(bank_train2, skew = TRUE, na.rm = TRUE)

kable(data.frame(ds_stats[1:5]), caption= "Data Summary (Part 1/3")
kable(data.frame(ds_stats[6:10]), caption= "Data Summary (Part 2/3)")
kable(data.frame(ds_stats[11:13]), caption= "Data Summary (Part 3/3)")

#head(bank_train2)

fun1 <- function(a, y) cor(y, a)
x<-bank_train2[,]
Correlation <- sapply(x, FUN = fun1, y=bank_train2$y) 

```

### Correlation of Variables with y 
Now we will produce the correlation table between the independent variables and the dependent variable

```{r, echo = FALSE, warning=FALSE, message=FALSE}

Correlation <- sort(Correlation, decreasing = TRUE)
#head(Correlation)
#kable(Correlation, caption = "Variable Correlation")
kable(data.frame(Correlation), caption = "Correlation between 'y' and predictor variables")

#str(bank_train2)
#str(bank_train)
#summary(bank_train2)

```

### Outliers

```{r, echo = FALSE, warning=FALSE, message=FALSE}

mdata<- select(bank_train2,  age, previous, duration, campaign, emp.var.rate, cons.price.idx, euribor3m,nr.employed)
mdata2 <- melt(mdata)

# Output the boxplot
p <- ggplot(data = mdata2, aes(x=variable, y=value)) + 
  geom_boxplot() + ggtitle("Outliers Identification")
p + facet_wrap( ~ variable, scales="free", ncol=4)
```

### Histograms of Variables

```{r, echo = FALSE, warning=FALSE, message=FALSE}

#move y to the last column
bank_train2 <- bank_train2 %>%
  select(-y, everything())

vars <- names(Correlation)

par(mfrow=c(2,4))
for (i in 2:ncol(bank_train2)) {
  hist(bank_train2[,vars[i]], main = vars[i], xlab = "")
}

```


### Analysis the link function 

In this section, we will investigate how our initial data aligns with a typical logistic model plot.

Recall the Logistic Regression is part of a larger class of algorithms known as Generalized Linear Model (glm). The fundamental equation of generalized linear model is:

$g(E(y)) = a+ Bx_1+B_2x_2+ B_3x_3+...$

where, g() is the link function, E(y) is the expectation of target variable and $B_0 + B_1x_1 + B_2x_2+B_3x_3$ is the linear predictor ( $B_0,B_1,B_2, B_3$ to be predicted). The role of link function is to 'link' the expectation of y to linear predictor.

In logistic regression, we are only concerned about the probability of outcome dependent variable ( success or failure). As described above, g() is the link function. This function is established using two things: Probability of Success (p) and Probability of Failure (1-p). p should meet following criteria: It must always be positive (since p >= 0) It must always be less than equals to 1 (since p <= 1).

Now let's investigate how our initial data model aligns with the above criteria. In other words, we will plot regression model plots for each variable and compare it to a typical logistic model plot:


The main objective in the transformations is to achieve linear relationships with the dependent variable (or, really, with its logit).

```{r, echo = FALSE, warning=FALSE, message=FALSE}

par(mfrow=c(2,4))
#Show in the order of Correlation
p = list()

for (i in 2:ncol(bank_train2)) {
  p[[i]] <- logi.hist.plot(bank_train2[,vars[i]],bank_train2$y,logi.mod = 1, type='hist', boxp=FALSE,col='gray', 
                           mainlabel = vars[i])
}

```


### Prepare test data

We will treat the test data the same way as the train data, and then apply models created using the treated train data.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

bank_test2<-bank_test

#update response variable to binary values of 0 and 1
levels(bank_test2$y) <- c(0, 1)
bank_test2$y <- as.numeric(levels(bank_test2$y))[bank_test2$y]

# age is numeric 

#create dummy variables for job values
for(level in unique(bank_test2$job)){
  bank_test2[paste("job", level, sep = "_")] <- ifelse(bank_test2$job == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$job <- NULL
#head(bank_test2)

#create dummy variables for marital values
#levels(bank_test2$marital)
for(level in unique(bank_test2$marital)){
  bank_test2[paste("marital", level, sep = "_")] <- ifelse(bank_test2$marital == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$marital <- NULL
#head(bank_test2)

#--------------------------------------------------------------------------
#education dummy variables primary, secondary tertiary, unknown and illiterate

#education_None
bank_test2$education_illiterate <- as.numeric(ifelse(bank_test2$education == "illiterate", 1, 0))
#table(bank_test2$education_Illiterate)

#education_Unknown
bank_test2$education_unknown <-as.numeric(ifelse(bank_test2$education == "unknown", 1, 0))
#table(bank_test2$education_Unknown)

#education_Primary
bank_test2$education_primary <- as.numeric(ifelse(bank_test2$education == "basic.4y" 
                                        | bank_test2$education == "basic.6y", 1, 0))
#table(bank_test2$education_Primary)

#education_Secondary
bank_test2$education_secondary <- as.numeric(ifelse(bank_test2$education == "basic.9y" 
                                        | bank_test2$education == "high.school", 1, 0))
#table(bank_test2$education_Secondary)

#education_Tertiary
bank_test2$education_tertiary <- as.numeric(ifelse(bank_test2$education == "professional.course" 
                                        | bank_test2$education == "university.degree", 1, 0))
#table(bank_test2$education_Tertiary)

#Delete original catagorical variable
bank_test2$education <- NULL
#---------------------------------------------------

# contact has 2 levels - 1 variable is required
#levels(bank_test2$default)
for(level in unique(bank_test2$default)){
  bank_test2[paste("default", level, sep = "_")] <- ifelse(bank_test2$default == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$default <- NULL


#levels(bank_test2$housing)
for(level in unique(bank_test2$housing)){
  bank_test2[paste("housing", level, sep = "_")] <- ifelse(bank_test2$housing == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$housing <- NULL

#levels(bank_test2$loan)
for(level in unique(bank_test2$loan)){
  bank_test2[paste("loan", level, sep = "_")] <- ifelse(bank_test2$loan == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$loan <- NULL

# contact has 2 levels - 1 variable is required
#levels(bank_test2$contact)
for(level in unique(bank_test2$contact)){
  bank_test2[paste("contact", level, sep = "_")] <- ifelse(bank_test2$contact == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$contact <- NULL

#levels(bank_test2$month)
for(level in unique(bank_test2$month)){
  bank_test2[paste("month", level, sep = "_")] <- ifelse(bank_test2$month == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$month <- NULL

#levels(bank_test2$day_of_week)
for(level in unique(bank_test2$day_of_week)){
  bank_test2[paste("day_of_week", level, sep = "_")] <- ifelse(bank_test2$day_of_week == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$day_of_week <- NULL

#duration is numeric
#campaign is numeric

#pdays is numeric
#dummy variable for pdays -previous contact yes or no ; 1 or 0  when 999
bank_test2$previous_contact <- as.numeric(ifelse(bank_test2$pdays == 999, 0, 1))

#previous is numeric

#levels(bank_test2$poutcome)
for(level in unique(bank_test2$poutcome)){
  bank_test2[paste("poutcome", level, sep = "_")] <- ifelse(bank_test2$poutcome == level, 1, 0)
}
#Delete original catagorical variable
bank_test2$poutcome <- NULL

# emp.var.rate is numeric
# cons.price.idx is numeric
# cons.conf.idx  is numeric
# euribor3m is numeric
# nr.employed is numeric


```


## Model Building


In this section, we will create 3 models. Aside from using original and transformed data, we will also be using different methods and functions such as Linear Discriminant Analysis, step function, and logit function to enhance our models. 

Below is our model definition: 

-Model 1- This model will be created using all the variables in train data set with logit function GLM. 

-Model 2: This model step function will be used to enhance the model 1. 

-Model 3- This model will be created using classification and regression tree. 

###Model 1

Taking the treated data and splitting into 80/20 to train model and validate the data.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

smp_size <- floor(0.80 * nrow(bank_train2))

## set the seed to make your partition reproductible
set.seed(123)

train_index <- sample(seq_len(nrow(bank_train2)), size = smp_size)

#DS_TARGET_FLAG_TRAIN<- bank_train2[train_index, ]
#DS_TARGET_FLAG_VALID <- bank_train2[-train_index, ]

DS_TARGET_FLAG_TRAIN<- bank_train2
DS_TARGET_FLAG_VALID <- bank_test2

```


```{r, echo = FALSE, warning=FALSE, message=FALSE}


model1 <- glm(y ~.,family=binomial(link='logit'),data=DS_TARGET_FLAG_TRAIN)
summary(model1)
anova(model1, test="Chisq")

library(pscl)
#the McFadden R^2 index can be used to assess the model fit.
pR2(model1)

fitted.results <- predict(model1,newdata=DS_TARGET_FLAG_VALID,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != DS_TARGET_FLAG_VALID$y)
print(paste('Accuracy',1-misClasificError))

#0.910779315367808 with 80/20 data
#0.914056809905317 with test data


```

### Model 2

```{r, echo = FALSE, warning=FALSE, message=FALSE}
```

### Model 3
```{r, echo = FALSE, warning=FALSE, message=FALSE}
```



## Model Selection

## Model Evaluation

## Statistical analysis
We used `r cite_r("r-references.bib")` for all our analyses.

## Interpretation and Disussion of Results

# Discussion and Conclusions
   conclude your findings, limitations, and suggest areas for future work

# References
   be sure to cite all references used in the report (APA format). 
```{r create_r-references}
r_refs(file = "r-references.bib")
```

# Appendix
  Supplemental tables and/or figures.
  R statistical programming code.

#```{r code=readLines(knitr::purl('https://raw.githubusercontent.com/kishkp/data621-ctg5/master/HW4/HW04_Group5.Rmd', documentation = 0)), eval = FALSE}
#```
   

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
\setlength{\parskip}{11pt}



